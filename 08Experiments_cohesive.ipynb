{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helper.functions import get_dataset_from_json\n",
    "# X_dict, y_str = get_dataset_from_json(\"featuresQuixote_cohesive.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_nltk(json_filename):\n",
    "    FOLDER = \".\\\\auxfiles\\\\json\\\\\"\n",
    "    with open(FOLDER + json_filename, \"r\") as f:\n",
    "        data_text = f.read()\n",
    "    return json.loads(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_nltk(filename, folds=2):\n",
    "    dataset = load_dataset_nltk(filename)\n",
    "    shuffle(dataset)\n",
    "    if folds > 0:\n",
    "        cut = len(dataset)//folds\n",
    "    else:\n",
    "        print(\"folds must be > 0\")\n",
    "        return None\n",
    "    train_set, test_set = dataset[cut:], dataset[:cut]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    acc = nltk.classify.accuracy(classifier, test_set)\n",
    "    keys = [\n",
    "        \"classifier\",\n",
    "        \"accuracy\",\n",
    "    ]\n",
    "    vals = [\n",
    "        classifier,\n",
    "        acc,\n",
    "    ]\n",
    "    return dict(zip(keys, vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quixote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiment\n",
    "\n",
    "Cohesive markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "filename1 = \"featuresQuixote_cohesive_tf.json\"\n",
    "\n",
    "experiment1 = [run_experiment_nltk(filename1, folds=10) for _ in range(1)]\n",
    "\n",
    "for run in experiment1:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment1])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     yet = None           Ormsby : Shelto =     22.1 : 1.0\n",
      "                 however = None           Shelto : Ormsby =      4.2 : 1.0\n",
      "                   since = None           Ormsby : Jarvis =      3.9 : 1.0\n",
      "                in short = None           Shelto : Jarvis =      3.7 : 1.0\n",
      "                although = None           Jarvis : Shelto =      3.1 : 1.0\n",
      "               therefore = None           Ormsby : Jarvis =      2.8 : 1.0\n",
      "                     now = None           Shelto : Ormsby =      2.7 : 1.0\n",
      "                likewise = None           Ormsby : Shelto =      2.4 : 1.0\n",
      "                   there = None           Jarvis : Ormsby =      2.3 : 1.0\n",
      "                    thus = None           Ormsby : Shelto =      2.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifiers1 = [run[\"classifier\"] for run in experiment1]\n",
    "\n",
    "for classifier in classifiers1:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Experiment\n",
    "\n",
    "Cohesive markers and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "filename2 = \"featuresQuixote_cohesive_punctuation_tfidf.json\"\n",
    "\n",
    "experiment2 = [run_experiment_nltk(filename2, folds=2) for i in range(1)]\n",
    "\n",
    "for run in experiment2:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment2])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     but = None           Ormsby : Shelto =      7.4 : 1.0\n",
      "                   , yet = None           Ormsby : Shelto =      6.5 : 1.0\n",
      "                  ; and, = None           Ormsby : Jarvis =      6.5 : 1.0\n",
      "                  , and, = None           Ormsby : Shelto =      4.7 : 1.0\n",
      "                   . and = None           Ormsby : Shelto =      4.1 : 1.0\n",
      "                   ; but = None           Ormsby : Jarvis =      3.9 : 1.0\n",
      "                    'and = None           Jarvis : Shelto =      3.9 : 1.0\n",
      "                    \"and = None           Shelto : Ormsby =      3.7 : 1.0\n",
      "                    'but = None           Jarvis : Shelto =      3.1 : 1.0\n",
      "                    here = None           Jarvis : Shelto =      2.9 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifiers2 = [run[\"classifier\"] for run in experiment2]\n",
    "\n",
    "for classifier in classifiers2:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Experiment\n",
    "\n",
    "Plain unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8783068783068783\n"
     ]
    }
   ],
   "source": [
    "filename = \"featuresQuixote_unigrams.json\"\n",
    "\n",
    "experiment = [run_experiment_nltk(filename, folds=2) for _ in range(1)]\n",
    "\n",
    "for run in experiment:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8783068783068783 0.0\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    hath = None           Jarvis : Shelto =     37.3 : 1.0\n",
      "                     has = None           Shelto : Ormsby =     25.4 : 1.0\n",
      "                 replied = None           Shelto : Ormsby =     21.5 : 1.0\n",
      "                     yet = None           Ormsby : Shelto =     21.1 : 1.0\n",
      "                scarcely = 1              Jarvis : Shelto =     14.3 : 1.0\n",
      "                   quoth = None           Ormsby : Shelto =     13.6 : 1.0\n",
      "               exclaimed = 1              Ormsby : Jarvis =     12.4 : 1.0\n",
      "                  whilst = 1              Shelto : Ormsby =     11.3 : 1.0\n",
      "                   about = None           Shelto : Ormsby =     11.3 : 1.0\n",
      "                   guess = 1              Jarvis : Ormsby =     10.8 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifiers = [run[\"classifier\"] for run in experiment]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "filename = \"featuresQuixote_trigrams_pos_punct_tfidf.json\"\n",
    "\n",
    "experiment = [run_experiment_nltk(filename, folds=5) for _ in range(1)]\n",
    "\n",
    "for run in experiment:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                NOUN . \" = None           Shelto : Ormsby =     48.1 : 1.0\n",
      "                , \" VERB = None           Shelto : Ormsby =     31.3 : 1.0\n",
      "         NOUN CCONJ VERB = None           Jarvis : Ormsby =     16.6 : 1.0\n",
      "                , ' VERB = None           Jarvis : Shelto =     16.5 : 1.0\n",
      "               PROPN , \" = None           Shelto : Ormsby =     15.4 : 1.0\n",
      "            \" VERB PROPN = None           Shelto : Ormsby =     14.5 : 1.0\n",
      "                , \" PRON = None           Shelto : Ormsby =     12.8 : 1.0\n",
      "                   . \" \" = None           Shelto : Ormsby =     12.0 : 1.0\n",
      "              ; ADP PRON = None           Ormsby : Jarvis =     11.3 : 1.0\n",
      "              \" PRON AUX = None           Shelto : Jarvis =     11.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifiers = [run[\"classifier\"] for run in experiment]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Experiment\n",
    "\n",
    "Plain bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7466666666666667\n",
      "Accuracy: 0.6133333333333333\n",
      "Accuracy: 0.72\n",
      "Accuracy: 0.72\n",
      "Accuracy: 0.68\n",
      "Accuracy: 0.6933333333333334\n",
      "Accuracy: 0.6533333333333333\n",
      "Accuracy: 0.6933333333333334\n",
      "Accuracy: 0.7733333333333333\n",
      "Accuracy: 0.6933333333333334\n",
      "Accuracy: 0.7333333333333333\n",
      "Accuracy: 0.6666666666666666\n",
      "Accuracy: 0.68\n",
      "Accuracy: 0.6933333333333334\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.6666666666666666\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.72\n",
      "Accuracy: 0.6533333333333333\n"
     ]
    }
   ],
   "source": [
    "filename = \"featuresQuixote_bigrams.json\"\n",
    "\n",
    "experiment = [run_experiment_nltk(filename, folds=5) for _ in range(20)]\n",
    "\n",
    "for run in experiment:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859999999999999 0.0015906666666666667\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [run[\"classifier\"] for run in experiment]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9066666666666666\n",
      "Accuracy: 0.8666666666666667\n",
      "Accuracy: 0.9066666666666666\n",
      "Accuracy: 0.9066666666666666\n",
      "Accuracy: 0.88\n",
      "Accuracy: 0.92\n",
      "Accuracy: 0.88\n",
      "Accuracy: 0.92\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9466666666666667\n",
      "Accuracy: 0.8933333333333333\n",
      "Accuracy: 0.9466666666666667\n",
      "Accuracy: 0.8933333333333333\n",
      "Accuracy: 0.92\n",
      "Accuracy: 0.8666666666666667\n",
      "Accuracy: 0.92\n",
      "Accuracy: 0.8\n",
      "Accuracy: 0.96\n",
      "Accuracy: 0.8933333333333333\n",
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "filename = \"featuresQuixote_bigrams_punct.json\"\n",
    "\n",
    "experiment = [run_experiment_nltk(filename, folds=5) for _ in range(20)]\n",
    "\n",
    "for run in experiment:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9020000000000001 0.0012137777777777772\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Experiment\n",
    "Plain trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30666666666666664\n",
      "Accuracy: 0.24\n",
      "Accuracy: 0.16\n",
      "Accuracy: 0.24\n",
      "Accuracy: 0.12\n",
      "Accuracy: 0.14666666666666667\n",
      "Accuracy: 0.16\n",
      "Accuracy: 0.09333333333333334\n",
      "Accuracy: 0.16\n",
      "Accuracy: 0.17333333333333334\n",
      "Accuracy: 0.21333333333333335\n",
      "Accuracy: 0.18666666666666668\n",
      "Accuracy: 0.30666666666666664\n",
      "Accuracy: 0.2\n",
      "Accuracy: 0.30666666666666664\n",
      "Accuracy: 0.21333333333333335\n",
      "Accuracy: 0.18666666666666668\n",
      "Accuracy: 0.12\n",
      "Accuracy: 0.25333333333333335\n",
      "Accuracy: 0.18666666666666668\n"
     ]
    }
   ],
   "source": [
    "filename = \"featuresQuixote_trigrams.json\"\n",
    "\n",
    "experiment = [run_experiment_nltk(filename, folds=5) for _ in range(20)]\n",
    "\n",
    "for run in experiment:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19866666666666669 0.0036782222222222225\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [run[\"classifier\"] for run in experiment]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"featuresQuixote_trigrams_punct.json\"\n",
    "\n",
    "experiment = [run_experiment_nltk(filename, folds=5) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Accuracy: 0.65\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.67\n",
      "Accuracy: 0.68\n",
      "Accuracy: 0.65\n",
      "Accuracy: 0.79\n",
      "Accuracy: 0.65\n",
      "Accuracy: 0.72\n",
      "Accuracy: 0.56\n",
      "Accuracy: 0.56\n",
      "Accuracy: 0.72\n",
      "Accuracy: 0.64\n",
      "Accuracy: 0.73\n",
      "Accuracy: 0.67\n",
      "Accuracy: 0.72\n",
      "Accuracy: 0.67\n",
      "Accuracy: 0.73\n",
      "Accuracy: 0.69\n",
      "Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "for run in experiment:\n",
    "    print(f\"Accuracy: {run['accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766666666666665 0.0032866666666666643\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ibsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6521739130434783\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 0.7391304347826086\n",
      "Accuracy: 0.6086956521739131\n",
      "Accuracy: 0.6956521739130435\n",
      "Accuracy: 0.782608695652174\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 0.6956521739130435\n",
      "Accuracy: 0.782608695652174\n",
      "Accuracy: 0.6956521739130435\n",
      "Accuracy: 0.782608695652174\n",
      "Accuracy: 0.6086956521739131\n",
      "Accuracy: 0.6521739130434783\n",
      "Accuracy: 0.6086956521739131\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.7391304347826086\n",
      "Accuracy: 0.6086956521739131\n",
      "Accuracy: 0.6086956521739131\n",
      "Accuracy: 0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "filename3 = \"featuresIbsen_cohesive.json\"\n",
    "\n",
    "experiment3 = [run_experiment_nltk(filename3, folds=10) for i in range(20)]\n",
    "\n",
    "for run in experiment3:\n",
    "    print(f\"Accuracy: {run['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7138297872340426 0.004638976912630147\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment3])\n",
    "print(accs.mean(), accs.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers3 = [run[\"classifier\"] for run in experiment3]\n",
    "\n",
    "for classifier in classifiers3:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9565217391304348\n",
      "Accuracy: 0.9565217391304348\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 0.7391304347826086\n",
      "Accuracy: 0.9565217391304348\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.9565217391304348\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 0.9130434782608695\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 0.9130434782608695\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.8695652173913043\n",
      "Accuracy: 0.8260869565217391\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "filename4 = \"featuresIbsen_cohesive_punctuation.json\"\n",
    "\n",
    "experiment4 = [run_experiment_nltk(filename4, folds=10) for i in range(20)]\n",
    "\n",
    "for run in experiment4:\n",
    "    print(\"Accuracy:\", run[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869565217391303 0.0665089501772972\n"
     ]
    }
   ],
   "source": [
    "accs = np.array([run[\"accuracy\"] for run in experiment4])\n",
    "print(accs.mean(), accs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers4 = [run[\"classifier\"] for run in experiment4]\n",
    "\n",
    "for classifier in classifiers4:\n",
    "    print(classifier.show_most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
