{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from helper.analysis import get_dataset_from_json\n",
    "from helper.analysis import JSON_FOLDER\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from typing import Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_files = [file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"features\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files = [file for file in features_files if \"Quixote\" in file.name and \"cohesive\" in file.name and \"punct\" in file.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[WindowsPath('auxfiles/json/featuresQuixote_cohesive_punct.json')]"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filtered_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict, y_str = get_dataset_from_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = v.fit_transform(X_dict), encoder.fit_transform(y_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = shuffle(X, y, random_state=24)\n",
    "\n",
    "dimension = X.shape[1]\n",
    "m, n = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cross-validation mean accuracy: 97.37% with a standard deviation: 2.61%\n"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "cv = cross_val_score(log_model, X_, y_, cv=10)\n",
    "print(f\"Cross-validation mean accuracy: {cv.mean():.2%} with a standard deviation: {cv.std():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9735449735449735\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[122,   2,   2],\n       [  2, 124,   0],\n       [  3,   1, 122]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "y_pred = cross_val_predict(log_model, X_, y_, cv=10)\n",
    "print(accuracy_score(y_, y_pred, normalize=True))\n",
    "confusion_matrix(y_, y_pred, labels=unique_labels(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "clf = log_model.fit(X_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.utils import return_n_most_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "most_relevant = return_n_most_important(clf=clf, v=v, encoder=encoder, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The 30 most relevant cohesive punct features for Archer are:\n\n too|. but,|: and|. that is|: but|) and|now.|, before|. now|before)|. there|again)|that is|. and,|! but|, after|too.|) now|--but|; and then|here|, then?|here.|, then.|still,|. certainly.|. indeed|(after|here--|: but,\n\n\nThe 30 most relevant cohesive punct features for Sharp are:\n\n ] and|] but|. then|] then|then,|--then|] now|[after|] there|before.|yet|[still|. and then|last.|, far|again!|first|then.|] here!|! and|; and|there.|now!|then?|certainly|then|, indeed.|to the left.|third|--there\n\n\n"
    }
   ],
   "source": [
    "for label in unique_labels(y_str):\n",
    "    print(f\"The {n} most relevant {' '.join(file.stem.split('_')[1:])} features for {label} are:\\n\\n {'|'.join(most_relevant[label])}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('spacy': conda)",
   "language": "python",
   "name": "python36764bitspacyconda81cbf537626c4c91a9ad866d10139160"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}