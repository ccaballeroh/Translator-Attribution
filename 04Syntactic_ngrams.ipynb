{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic information extraction"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outputs the syntactic analysis with the Stanford output format for every file in the Ibsen and Quixote corpus. A script in Python 3 can parse those files and produce files with *noncontinous* syntactic n-grams."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes a Python 3 kernel in order to run the script `sn_grams3.py`. The arguments for said file are the input file to analyze, the output file name where to write the n-grams, the minimun size of n-grams, the maximum size of n-grams, the maximum number of children and an option (0 for word sn-grams).\n",
    "\n",
    "There's an older file named `sn_grams_.py` in the same folder. I changed the way to look for the words in the Stanford format from na√Øve (using python `find` and `rfind` strings methods) to using regex. And yet another backup file named `sn_grams.py` with this change implemented, but only functional in Python 2."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper.syntactic as syn\n",
    "from helper.analysis import save_dataset_to_json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "file saved\nfile saved\nfile saved\nfile saved\n"
    }
   ],
   "source": [
    "for author in [\"Quixote\", \"Ibsen\"]:\n",
    "    syn.main(author)\n",
    "    syn.sn_generation(author)\n",
    "    for n in range(2,4):\n",
    "        FILE_TEMPLATE = f\"features{author}_synctactic_n{n}\" \n",
    "        save_dataset_to_json(syn.syntactic_features(author, n=n), FILE_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_sn(author):\n",
    "    from pathlib import Path\n",
    "    TXT_FOLDER = Path(fr\"./auxfiles/txt/{author}/\")\n",
    "    for filename in TXT_FOLDER.iterdir():\n",
    "        filename.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_sn(\"Quixote\")\n",
    "cleaning_sn(\"Ibsen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('spacy': conda)",
   "language": "python",
   "name": "python36764bitspacyconda81cbf537626c4c91a9ad866d10139160"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}