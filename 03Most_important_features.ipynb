{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.7 64-bit ('spacy': conda)",
      "language": "python",
      "name": "python36764bitspacyconda81cbf537626c4c91a9ad866d10139160"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7-final"
    },
    "colab": {
      "name": "03Most_important.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccaballeroh/Translator-Attribution/blob/master/03Most_important_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxRkXRnu6ymW",
        "colab_type": "text"
      },
      "source": [
        "# Extraction of Most Relevant Features\n",
        "\n",
        "On this notebook, we extract the most relevant features in the classification process for each translator. In order to do this, we can retrieve the learned weights from a linear classifier (e.g., Logistic Regression, although a Support Vector Machine using a linear *kernel* also have those properties as well as the Naïve Bayes classifier) and get the $n$ largest. The corresponding $n$ features would thus be the most relevant for each class. In case of a binary classifier, the $n$ largest weights would correspond to the *positive* class, whereas the $n$ most negative weights would correspond to the *negative* class.\n",
        "\n",
        "Since scikit-learn trains $N$ binary classifiers when given an N-class multiclass problem, we can retrieve the $n$ largest weights&mdash;and their corresponding features&mdash;for each classifier. This notebook saves to disk the $n$ most relevant features for each translator in the corpora for each feature set and for three classifiers: logistic regression, linear support vector machine, and a naïve Bayes classifier. The results are saved as bar plots and also tabular (CSV, HTML and, $\\LaTeX$) in the `results\\figs\\most` and `results\\tables` folders respectively.\n",
        "\n",
        "Also on this Notebook, there's code for generating the confusion matrices product of training a Logistic Regression classifier on the *entire* dataset. We train on the entire dataset because we have proven already&mdash;via 10-fold cross-validation&mdash;that the accuracy of the classifier is high enough. The confusion matrices are generated for each feature set and are also saved to disk in the `results\\figs\\cm` folder.\n",
        "\n",
        "\n",
        "**NOTE:** This notebook can be run on Google Colab after having followed the instructions found in the [README](./README.md) file in this repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jZ3uI9mRKh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HK4MsUARPCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    ROOT = Path(r\"./drive/My Drive/Translator-Attribution\")\n",
        "    sys.path.insert(0,f\"{ROOT}/\")\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "else:\n",
        "    from helper.analysis import ROOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COM-qODNRCqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from helper.analysis import get_dataset_from_json\n",
        "from helper.analysis import JSON_FOLDER\n",
        "from helper.utils import return_n_most_important\n",
        "from pathlib import Path\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from typing import Dict, List\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErR8Mas46yml",
        "colab_type": "text"
      },
      "source": [
        "The following cell assigns the locations where to save the tables and figures. It created the folders in case they don't exist yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiD6g0VFRCq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESULTS_FOLDER = Path(fr\"{ROOT}/results/\")\n",
        "if not RESULTS_FOLDER.exists():\n",
        "    RESULTS_FOLDER.mkdir()\n",
        "\n",
        "TABLES_FOLDER = RESULTS_FOLDER / \"tables\"\n",
        "if not TABLES_FOLDER.exists():\n",
        "    TABLES_FOLDER.mkdir()\n",
        "\n",
        "FIGS_FOLDER = RESULTS_FOLDER / \"figs\"\n",
        "if not FIGS_FOLDER.exists():\n",
        "    FIGS_FOLDER.mkdir()\n",
        "\n",
        "CONF_MAT_FOLDER = FIGS_FOLDER / \"cm\"\n",
        "if not CONF_MAT_FOLDER.exists():\n",
        "    CONF_MAT_FOLDER.mkdir()\n",
        "\n",
        "MOST_RELEVANT_FOLDER = FIGS_FOLDER / \"most\"\n",
        "if not MOST_RELEVANT_FOLDER.exists():\n",
        "    MOST_RELEVANT_FOLDER.mkdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkkRVjg86ymq",
        "colab_type": "text"
      },
      "source": [
        "These are the files to process. They are the entirety of the feature sets obtained using [01Processing](./01Processing.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F_KDYeF6ymr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "features_files = [file for file in JSON_FOLDER.iterdir() if file.name.startswith(\"features\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2spuxmx76ymv",
        "colab_type": "text"
      },
      "source": [
        "## Most Relevant Features\n",
        "\n",
        "The next cells define a couple of functions to generate and save the bar plots and tabular data of the $n=15$ most relevant features in the classification process for each translator and each feature set using three classifiers: Logistic Regression, Linear Support Vector Machine, and Naïve Bayes.\n",
        "\n",
        "To do feature selection using the $\\chi^2$ statistic, leave the following cell to `True`. Otherwise, change it to `False`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDXpqk-amUOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURE_SELECTION = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgILCXSfRCrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "def plot_most_relevant(\n",
        "    *, data: Dict[str, pd.DataFrame], translator: str, model: str, file: Path\n",
        ") -> None:\n",
        "    \"\"\"Saves a bar plot of the most relevant features for a translator using a classifier.\n",
        "\n",
        "    The function takes a list of data frames with the n most relevant weights and features\n",
        "    for a classifier for a translator.\n",
        "\n",
        "    Parameters:\n",
        "    data: Dict[str, pd.DataFrame]  - The key is the translator name and the DataFrame\n",
        "                                 contains two Series: 'Weight' and 'Feature'\n",
        "    translator: str             - Name of the translator\n",
        "    model: str                  - Name of the model (classifier) used\n",
        "    file: Path                  - Feature set used to train the model\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    plot = sns.barplot(\n",
        "        x=data[translator][\"Weight\"], y=data[translator][\"Feature\"], palette=\"cividis\",\n",
        "    )\n",
        "    features = \" \".join(file.stem.split(\"_\")[1:])\n",
        "    plot.set(title=f\"{translator} - {model} - {features}\")\n",
        "    fig = plot.get_figure()\n",
        "    fig.savefig(\n",
        "        MOST_RELEVANT_FOLDER / f\"{file.stem}_{translator}_{model}.png\", bbox_inches=\"tight\",\n",
        "    )\n",
        "    fig.clf()\n",
        "\n",
        "def save_tables(*, df:pd.DataFrame, translator:str, file:Path, model_name:str)-> None:\n",
        "    \"\"\"Saves to disk the tabular data of the n most relevant features of a classifier.\n",
        "\n",
        "    Takes a DataFrame containing the n most relevant features and their weights.\n",
        "\n",
        "    Parameters:\n",
        "    df: pd.DataFrame        - Contains two series: 'Weights' and 'Features'\n",
        "    translator: str         - Name of the translator\n",
        "    file: Path              - Feature set used to train the classifier\n",
        "    model_name: str         - Name of the classifier used\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    df.to_csv(TABLES_FOLDER / f\"{file.stem}_{translator}_{model_name}.csv\", float_format='%.4f')\n",
        "\n",
        "    latex = df.to_latex(float_format=lambda x: '%.4f' % x)\n",
        "    with open(TABLES_FOLDER /f\"{file.stem}_{translator}_{model_name}.tex\", \"w\") as f:\n",
        "        f.write(latex)\n",
        "    \n",
        "    html = df.to_html(float_format='%.4f')\n",
        "    with open(TABLES_FOLDER /f\"{file.stem}_{translator}_{model_name}.html\", \"w\") as f:\n",
        "        f.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOJ1kKwV6ym1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model_name in [\"LogisticRegression\", \"SVM\", \"NaiveBayes\"]:\n",
        "    for author in [\"Ibsen\", \"Quixote\"]:\n",
        "        for file in [file for file in features_files if author in file.name]:\n",
        "            X_dict, y_str = get_dataset_from_json(file)\n",
        "            \n",
        "            v = DictVectorizer(sparse=True)\n",
        "            encoder = LabelEncoder()         \n",
        "            \n",
        "            X, y = v.fit_transform(X_dict), encoder.fit_transform(y_str)\n",
        "\n",
        "            if FEATURE_SELECTION:            \n",
        "                chi2_selector = SelectKBest(chi2, k=50)\n",
        "                X = chi2_selector.fit_transform(X, y)\n",
        "                all_names = np.array(v.get_feature_names())\n",
        "                feature_names = list(all_names[chi2_selector.get_support()])\n",
        "            else:\n",
        "                feature_names = v.get_feature_names()\n",
        "\n",
        "\n",
        "            X_, y_ = shuffle(X, y, random_state=24)\n",
        "\n",
        "            if model_name == \"LogisticRegression\":\n",
        "                model = LogisticRegression()\n",
        "            elif model_name == \"SVM\":\n",
        "                model = LinearSVC()\n",
        "            elif model_name == \"NaiveBayes\":\n",
        "                model = MultinomialNB()\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "\n",
        "            clf = model.fit(X_, y_)\n",
        "\n",
        "            most_relevant = return_n_most_important(\n",
        "                                                    clf=clf,\n",
        "                                                    feature_names=feature_names,\n",
        "                                                    encoder=encoder,\n",
        "                                                    n=15\n",
        "                            )\n",
        "\n",
        "            for translator in encoder.classes_:\n",
        "                plot_most_relevant(data=most_relevant, translator=translator, model=model_name, file=file)\n",
        "                df = most_relevant[translator]\n",
        "                save_tables(df=df, translator=translator, file=file, model_name=model_name)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEW-0ZAO6ym5",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrices\n",
        "\n",
        "The following code generates the Confusion Matrices for all the feature sets using a logistic regression classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EWgJR3U6ym6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=1.4)\n",
        "for author in [\"Ibsen\", \"Quixote\"]:\n",
        "    for file in [file for file in features_files if author in file.name]:\n",
        "        X_dict, y_str = get_dataset_from_json(file)\n",
        "        v = DictVectorizer(sparse=True)\n",
        "        encoder = LabelEncoder()\n",
        "        \n",
        "        X, y = v.fit_transform(X_dict), encoder.fit_transform(y_str)\n",
        "        \n",
        "        if FEATURE_SELECTION:            \n",
        "            chi2_selector = SelectKBest(chi2, k=50)\n",
        "            X = chi2_selector.fit_transform(X, y)\n",
        "\n",
        "        X_, y_ = shuffle(X, y, random_state=24)    \n",
        "        \n",
        "        log_model = LogisticRegression()\n",
        "\n",
        "        y_pred = cross_val_predict(log_model, X_, y_, cv=10)\n",
        "        cm = confusion_matrix(y_, y_pred, labels=unique_labels(y_))\n",
        "\n",
        "        df = pd.DataFrame(cm, index=encoder.classes_, columns=encoder.classes_)\n",
        "\n",
        "        cm_plot = sns.heatmap(df, annot=True, cbar=None, cmap=\"Blues\", fmt=\"d\", annot_kws={\"size\":18})\n",
        "        plt.title(f\"{' '.join(file.stem.split('_')[1:])}\")\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel(\"True translator\")\n",
        "        plt.xlabel(\"Predicted translator\")\n",
        "        plt.savefig(CONF_MAT_FOLDER/f\"cm_{file.stem}.png\", bbox_inches=\"tight\", )\n",
        "        plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}